{
    "conversion_errors": {
        "RuntimeError: 0INTERNAL ASSERT FAILED": {
            "title": "Conversion to ONNX Failed",
            "what_happened": "Hugging Face tool failed to convert the model to ONNX format.",
            "details": "Failed to trace static exec graph from PyTorch model.",
            "what_to_do": "See Troubleshooting for more details: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html"
        },
        "onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument": {
            "title": "Conversion to ONNX Failed",
            "what_happened": "Hugging Face tool failed to convert the model to ONNX format.",
            "details": "The tokenizer generated data for the input that is not present in the model. The tokenizer does not match this model.",
            "what_to_do": "Try to create your own repository with the model and select the right tokenizer. See Troubleshooting for more details: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html"
        },
        "Connection error, and we cannot find the requested files in the cached path": {
            "title": "Connection error. Check the internet connection and proxy and try again.",
            "what_happened": "Connection error. Check the internet connection and proxy and try again.",
            "details": "Connection error. Check the internet connection and proxy and try again.",
            "what_to_do": "Connection error. Check the internet connection and proxy and try again."
        },
        "TypeError: not a string": {
            "title": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "what_happened": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "details": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "what_to_do": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself."
        },
        "Error(s) in loading state_dict": {
            "title": "Conversion to ONNX Failed",
            "what_happened": "Hugging Face tool failed to load PyTorch model.",
            "details": "Error while loading the state dictionary of the PyTorch model. Model configuration might not match the model weights in the Hugging Face repository.",
            "what_to_do": "Try to initialize the model, save the model locally and convert it using the instructions from Troubleshooting: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html"
        },
        "sequence item 0: expected str instance": {
            "title": "Conversion to ONNX Failed ",
            "what_happened": "Hugging Face tool failed to convert the model to ONNX format.",
            "details": "Failed to generate dummy input for PyTorch model tracing. Required tokenizer.unk_token is not set.",
            "what_to_do": "Convert the model to ONNX using PyTorch conversion tool and import it as the original model in the DL Workbench. See Troubleshooting for more details and available solutions: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html "
        },
        "expected str, bytes or os.PathLike object": {
            "title": "Conversion to ONNX Failed ",
            "what_happened": "Some tokenizer files are missing in the repository.",
            "details": "Some tokenizer files are missing in the repository or tokenizer files have wrong type/name.",
            "what_to_do": "Convert the model to ONNX using PyTorch conversion tool and import it as the original model in the DL Workbench. See Troubleshooting for more details and available solutions: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html ."
        },
        "path should be string, bytes, os.PathLike or integer": {
            "title": "Conversion to ONNX Failed",
            "what_happened": "Some tokenizer files are missing in the repository.",
            "details": "Some tokenizer files are missing in the repository or tokenizer files have wrong type/name.",
            "what_to_do": "Convert the model to ONNX using PyTorch conversion tool and import it as the original model in the DL Workbench. See Troubleshooting for more details and available solutions: https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Troubleshooting.html"
        },
        "The state dictionary of the model you are training to load is corrupted": {
            "title": "Cannot initialize the model form the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself.",
            "what_happened": "Cannot initialize the model form the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself.",
            "details": "Cannot initialize the model form the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself.",
            "what_to_do": "Cannot initialize the model form the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself."
        },
        "No such file or directory (os error 2)": {
            "title": "Cannot initialize tokenizer from the repository.",
            "what_happened": "Cannot initialize tokenizer from the repository.",
            "details": "Cannot initialize tokenizer from the repository.",
            "what_to_do": "Cannot initialize tokenizer from the repository."
        },
        "Can't load tokenizer for": {
            "title": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "what_happened": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "details": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
            "what_to_do": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself."
        },
        "Exporting model exceed maximum protobuf size of 2GB": {
            "title": "Cannot convert a large model to ONNX.",
            "what_happened": "Cannot convert a large model to ONNX.",
            "details": "Cannot convert a large model to ONNX.",
            "what_to_do": "Cannot convert a large model to ONNX."
        },
        "Connection error": {
            "title": "Connection error, check the internet connection and proxy and try again.",
            "what_happened": "Connection error, check the internet connection and proxy and try again.",
            "details": "Connection error, check the internet connection and proxy and try again.",
            "what_to_do": "Connection error, check the internet connection and proxy and try again."
        },
        "Model and config inputs doesn't match": {
            "title": "Cannot convert model to ONNX: model and config inputs doesn't match. The repository might contain wrong tokenizer type. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
            "what_happened": "Cannot convert model to ONNX: model and config inputs doesn't match. The repository might contain wrong tokenizer type. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
            "details": "Cannot convert model to ONNX: model and config inputs doesn't match. The repository might contain wrong tokenizer type. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
            "what_to_do": "Cannot convert model to ONNX: model and config inputs doesn't match. The repository might contain wrong tokenizer type. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself."
        },
        "Wrong index found for [MASK]": {
            "title": "Cannot initialize tokenizer from the model repository.",
            "what_happened": "Cannot initialize tokenizer from the model repository.",
            "details": "Cannot initialize tokenizer from the model repository.",
            "what_to_do": "Cannot initialize tokenizer from the model repository."
        },
        "Expecting value: line": {
            "title": "Cannot initialize tokenizer or config from the model repository: the json file is corrupted.",
            "what_happened": "Cannot initialize tokenizer or config from the model repository: the json file is corrupted.",
            "details": "Cannot initialize tokenizer or config from the model repository: the json file is corrupted.",
            "what_to_do": "Cannot initialize tokenizer or config from the model repository: the json file is corrupted."
        },
        "UnexpectedTransformersONNXError": {
            "title": "1",
            "what_happened": "2",
            "details": "3",
            "what_to_do": "4"
        }
    },
    "filter": {
        "no_config": {
            "title": "The model has no config in the repository. Try importing another model",
            "what_happened": "The model has no config in the repository. Try importing another model",
            "details": "The model has no config in the repository. Try importing another model",
            "what_to_do": "The model has no config in the repository. Try importing another model"
        },
        "no_model_type": {
            "title": "Model config has no model type. Try importing another model",
            "what_happened": "Model config has no model type. Try importing another model",
            "details": "Model config has no model type. Try importing another model",
            "what_to_do": "Model config has no model type. Try importing another model"
        },
        "not_supported_model_type": {
            "title": "Model type {} is not supported. Try converting the model to a supported format or importing another model",
            "what_happened": "Model type {} is not supported. Try converting the model to a supported format or importing another model",
            "details": "Model type {} is not supported. Try converting the model to a supported format or importing another model",
            "what_to_do": "Model type {} is not supported. Try converting the model to a supported format or importing another model"
        },
        "not_supported_sequence_classification": {
            "title": "Sequence classification feature is not supported for model type {}",
            "what_happened": "Sequence classification feature is not supported for model type {}",
            "details": "Sequence classification feature is not supported for model type {}",
            "what_to_do": "Sequence classification feature is not supported for model type {}"
        },
        "decoder_not_supported": {
            "title": "The model type {} contains transformer decoder that is not supported by the DL Workbench. Try importing another model",
            "what_happened": "The model type {} contains transformer decoder that is not supported by the DL Workbench. Try importing another model",
            "details": "The model type {} contains transformer decoder that is not supported by the DL Workbench. Try importing another model",
            "what_to_do": "The model type {} contains transformer decoder that is not supported by the DL Workbench. Try importing another model"
        },
        "missing_tokenizer_files": {
            "title": "Tokenizer files are missing. Check if the model type and the tokenizer type match",
            "what_happened": "Tokenizer files are missing. Check if the model type and the tokenizer type match",
            "details": "Tokenizer files are missing. Check if the model type and the tokenizer type match",
            "what_to_do": "Tokenizer files are missing. Check if the model type and the tokenizer type match"
        }
    }
}
