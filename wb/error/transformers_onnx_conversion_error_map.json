{
    "conversion_errors": {
        "RuntimeError: 0INTERNAL ASSERT FAILED": "PyTorch JiT trace error. Try converting the model to ONNX format.",
        "onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument": "Wrong tokenizer type in the repository. To convert the model, try contacting the authors of the repository or cloning the repository and fixing the tokenizer yourself.",
        "Connection error, and we cannot find the requested files in the cached path": "Connection error. Check the internet connection and proxy and try again.",
        "TypeError: not a string": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
        "Error(s) in loading state_dict": "Cannot initialize the model from the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself.",
        "sequence item 0: expected str instance": "[unk] and [pad] tokens for tokenizer are not set.",
        "expected str, bytes or os.PathLike object": "Not enough files for the tokenizer initialization in the repository. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
        "path should be string, bytes, os.PathLike or integer": "Not enough files for the tokenizer initialization in the repository. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
        "The state dictionary of the model you are training to load is corrupted": "Cannot initialize the model form the repository. Try contacting the authors of the repository or cloning the repository and fixing the issue yourself.",
        "No such file or directory (os error 2)": "Cannot initialize tokenizer from the repository.",
        "Can't load tokenizer for": "Failed to load tokenizer during model conversion to ONNX. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
        "Exporting model exceed maximum protobuf size of 2GB": "Cannot convert a large model to ONNX.",
        "Connection error": "Connection error, check the internet connection and proxy and try again.",
        "Model and config inputs doesn't match": "Cannot convert model to ONNX: model and config inputs doesn't match. The repository might contain wrong tokenizer type. Try contacting the repository authors or cloning the repository and adding the fixing the files yourself.",
        "Wrong index found for [MASK]": "Cannot initialize tokenizer from the model repository.",
        "JSONDecodeError": "Cannot initialize tokenizer from the model repository: the json file is corrupted.",
        "PreValidationTokenizerError": "Cannot initialize tokenizer from the repository. Try initializing the tokenizer before starting the model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself.",
        "PreValidationModelConfigError": "Cannot initialize configuration file from the repository. Try initializing the configuration file before starting model import. If you detect an error, contact the authors of the repository or clone the repository and fix the file yourself."
    },
    "filter": {
        "no_config": "The model has no config in the repository. Try importing another model",
        "no_model_type": "Model config has no model type. Try importing another model",
        "not_supported_model_type": "Model type {} is not supported. Try converting the model to a supported format or importing another model",
        "not_supported_sequence_classification": "Sequence classification feature is not supported for model type {}",
        "decoder_not_supported": "The model type {} contains transformer decoder that is not supported by the DL Workbench. Try importing another model",
        "missing_tokenizer_files": "Tokenizer files are missing. Check if the model type and the tokenizer type match"
    }
}
