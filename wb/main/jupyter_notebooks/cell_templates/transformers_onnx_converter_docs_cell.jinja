### Get ONNX model from Hugging Face Hub

#### Motivation

Most of the models on the Hugging Face Hub are stored in the PyTorch format.
To get an Intermediate Representation (IR) - preferred model format to work with OpenVINO - the model should be converted to ONNX first.
One can do this `transformers.onnx` CLI tool from the Transformers library, which is external to OpenVINO.

#### Main usage

`transformers.onnx` tool takes the name of the model repository from Hugging Face Hub and the task that the model should solve.
Then it downloads all necessary files, converts the model to ONNX format, and checks the resulting model.

#### Description

`transformers.onnx` will execute the following steps:

1. Download the model files and tokenizer files from the Hugging Face Hub.
1. Generate the dummy input with the tokenizer and pass it to the model to trace the model execution graph.
1. Use the execution graph to generate ONNX model.
1. Check that the result model output is close to the original model output.

To learn more about this CLI tool read the [documentation](https://huggingface.co/docs/transformers/main/en/serialization#onnx).

#### Used Command-Line Arguments

<details>
<summary>View transformers.onnx command-line arguments</summary>

{{ CLIToolEnum.transformers_onnx.format_to_markdown_table() | safe }}

</details>
